# This configuration creates a server that does nothing else besides logging
# some data as explained in https://github.com/mozilla/pdf.js/issues/7312.
#
# Method: POST
# Path  : /logpdfjs
# Request headers:
# - Deduplication-ID: hexadecimal string of length 32.
# - User-Agent: At most 1010 characters.
# - Extension-Version: 1 - 24 characters (up to 4 uint16_t separated by dot).
#
# The following data is logged:
# - Request time in ISO 8601 format.
# - The above request headers.
#
#
# This design was chosen for the following reasons:
#
# - Third-party web pages cannot forge the request, because of the custom header
#   requirement. This header can thus only be set through the XMLHttpRequest or
#   fetch API. However, that is blocked unless the request is allowed via CORS.
#   A custom header is a non-simple request, so the POST request will always be
#   preceded by an OPTIONS request. This is rejected by the server.
#
# - The logged information is minimal to avoid any privacy risks.
#
# - Note that fake data (i.e. requests made via curl, etc.) are tolerated.

# First the fixed-format values, then the arbitrary-value UA string.
log_format pdfjs
    '$time_iso8601 '
    '$http_deduplication_id '
    '$http_extension_version '
    '"$http_user_agent" ';

map $http_user_agent $has_valid_headers_2 {
    '~^.{1,1000}$' 1;
}
map $http_deduplication_id $has_valid_headers_1 {
    '~^[0-9a-f]{32}$' $has_valid_headers_2;
}
map $http_extension_version $has_valid_headers {
    # The number of parts must be between 1 and 4 (inclusive) and each part
    # is separated by a dot. Each part must fit in a 16-bit integer, i.e.
    # between 0 and 65535 (inclusive).
    '~^(([0-5]?[0-9]{1,4}|6([0-4][0-9]{3}|5([0-4][0-9]{2}|5([0-2][0-9]|3[0-5]))))(\.(?!$)|$)){1,4}$' $has_valid_headers_1;
}

server {
    # TODO: Specify actual port:ip
    listen 8080;
    listen 8443 ssl;
    server_name pdjs.robwu.nl;
    ssl_certificate     pdjs.robwu.nl.crt;
    ssl_certificate_key pdjs.robwu.nl.key;
    ssl_session_timeout 1d;
    ssl_session_cache shared:SSL:50m;
    ssl_session_tickets off;

    ssl_protocols       TLSv1.2;
    ssl_ciphers 'ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256';
    ssl_prefer_server_ciphers on;
    # TODO OCSP stapling? (Chrome doesn't check OCSP, so...)

    access_log off;
    log_not_found off;
    log_subrequest off;
    max_ranges 0;

    # Restrict length of headers. Only the User-Agent header has to fit in here.
    client_header_buffer_size 1k;
    large_client_header_buffers 4 1k;

    # We don't expect a request body, so reject any value.
    client_max_body_size 1;
    keepalive_timeout 0;

    location = /logpdfjs {
        if ($request_method != POST) {
            return 405;
        }
        if ($has_valid_headers) {
            access_log pdfjs.log pdfjs;
            return 204;
        }
        return 400;
    }

    location = /robots.txt {
        return 200 'User-Agent: *
Disallow: /
';
    }

    location / {
        return 404;
    }
}

# vim: syntax=nginx smartindent
